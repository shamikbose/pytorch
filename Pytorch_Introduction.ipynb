{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch_Introduction",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfyBkfD6gE1k"
      },
      "source": [
        "# Feedfoward Neural Network in Pytorch\r\n",
        "Coding a basic feedforward neural network in Pytorch. We will be building a CIFAR-10 classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1sDUm07hATJ"
      },
      "source": [
        "import torch\r\n",
        "from torch import nn, optim\r\n",
        "from torch.autograd.variable import Variable\r\n",
        "from torchvision import transforms, datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U7HnPfBqnah"
      },
      "source": [
        "* Get the training and test data\r\n",
        "* Convert the data from [0,1] to [-1,-1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wd0JfDNhYN9"
      },
      "source": [
        "def cifar_data(trainTrue: bool):\r\n",
        "    compose = transforms.Compose(\r\n",
        "        [transforms.ToTensor(),\r\n",
        "         transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\r\n",
        "        ])\r\n",
        "    out_dir = './dataset'\r\n",
        "    return datasets.CIFAR10(root=out_dir, train=trainTrue, transform=compose, download=True)\r\n",
        "\r\n",
        "train_data=cifar_data(trainTrue=True)\r\n",
        "test_data=cifar_data(trainTrue=False)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6uo6v6grgZ1"
      },
      "source": [
        "Define the classes and the parameters for the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K1PlmPnpxQP"
      },
      "source": [
        "classes = ['plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck']\r\n",
        "batch_size=128\r\n",
        "random_seed=42"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUjdMSobt2DW"
      },
      "source": [
        "Create the dataloaders for the train and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErdM6eS1rfQI"
      },
      "source": [
        "train_loader=torch.utils.data.DataLoader(train_data,batch_size=batch_size,shuffle=True)\r\n",
        "test_loader=torch.utils.data.DataLoader(test_data,batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRwdpt1ltw5-"
      },
      "source": [
        "Define the feedforward network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upoKj3ncrnOC"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F \r\n",
        "class FFNet(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(FFNet,self).__init__()\r\n",
        "    self.fc0=nn.Linear(3*32*32, 1024)\r\n",
        "    self.fc1=nn.Linear(1024,512)\r\n",
        "    self.fc2=nn.Linear(512,128)\r\n",
        "    self.fc3=nn.Linear(128,10)\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    x = x.view(x.size(0), -1)\r\n",
        "    x=self.fc0(x)\r\n",
        "    x=self.fc1(x)\r\n",
        "    x=self.fc2(x)\r\n",
        "    x=self.fc3(x)\r\n",
        "    return x\r\n",
        "\r\n",
        "ff_net=FFNet()\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CCXMmwZt673"
      },
      "source": [
        "Define loss function and an optimizer\r\n",
        "\r\n",
        "For this case, we are using the Cross Entropy Loss and the SGD optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5slup2__tlsk"
      },
      "source": [
        "import torch.optim as optim\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = optim.SGD(ff_net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Nz-VnFAut2z"
      },
      "source": [
        "num_epochs=10\r\n",
        "for epoch in range(num_epochs):\r\n",
        "  running_loss=0.0\r\n",
        "\r\n",
        "  for i, data in enumerate(train_loader, 0):\r\n",
        "\r\n",
        "    # get the inputs; data is a list of [inputs, labels]\r\n",
        "    inputs, labels = data\r\n",
        "\r\n",
        "    # zero the parameter gradients\r\n",
        "    optimizer.zero_grad()\r\n",
        "\r\n",
        "    # forward + backward + optimize\r\n",
        "    outputs = ff_net(inputs)\r\n",
        "    loss = criterion(outputs, labels)\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    # print statistics\r\n",
        "    running_loss += loss.item()\r\n",
        "    if i % 100 == 99:    # print every 2000 mini-batches\r\n",
        "        print('[Epoch %d, Iteration %5d] loss: %.3f' %\r\n",
        "              (epoch + 1, i + 1, running_loss / 2000))\r\n",
        "        running_loss = 0.0\r\n",
        "\r\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9ND-ZoVyZ_c"
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\r\n",
        "dataiter=iter(test_loader)\r\n",
        "images,labels=dataiter.next()\r\n",
        "outputs=ff_net(images)\r\n",
        "print(f1_score(torch.max(outputs.data,1)[-1],labels,average=\"micro\"))\r\n",
        "print(accuracy_score(torch.max(outputs.data,1)[-1],labels))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKep4THe03Hn"
      },
      "source": [
        "# Running it on GPU\r\n",
        "We will now move this network to the GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD-l75f2zcTu"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk6aszvOJLI9"
      },
      "source": [
        "Reinitialize train and test loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y9Nr3PiJITS"
      },
      "source": [
        "train_loader=torch.utils.data.DataLoader(train_data,batch_size=batch_size,shuffle=True)\r\n",
        "test_loader=torch.utils.data.DataLoader(test_data,batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqKlRAml4iEr"
      },
      "source": [
        "We need to move the following things from the CPU to the GPU\r\n",
        "* The model\r\n",
        "* The optimizer, since it uses the parameters from the pervious instantiation of the model\r\n",
        "* The data i.e. inputs and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s90iiw4Z1A24"
      },
      "source": [
        "ff_net=ff_net.to(device)\r\n",
        "optimizer = optim.SGD(ff_net.parameters(), lr=0.001, momentum=0.9)\r\n",
        "num_epochs=100\r\n",
        "for epoch in range(num_epochs):\r\n",
        "  running_loss=0.0\r\n",
        "\r\n",
        "  for i, data in enumerate(train_loader, 0):\r\n",
        "\r\n",
        "    # get the inputs; data is a list of [inputs, labels]\r\n",
        "    inputs, labels = data[0].to(device), data[1].to(device)\r\n",
        "\r\n",
        "    # zero the parameter gradients\r\n",
        "    optimizer.zero_grad()\r\n",
        "\r\n",
        "    # forward + backward + optimize\r\n",
        "    outputs = ff_net(inputs)\r\n",
        "    loss = criterion(outputs, labels)\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    # print statistics\r\n",
        "    running_loss += loss.item()\r\n",
        "    if i % 100 == 99:\r\n",
        "        print('[Epoch %d, Iteration %5d] loss: %.3f' %\r\n",
        "              (epoch + 1, i + 1, running_loss / 2000))\r\n",
        "        running_loss = 0.0\r\n",
        "\r\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNjGNP9B1cZ4"
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\r\n",
        "dataiter=iter(test_loader)\r\n",
        "images,labels=dataiter.next()\r\n",
        "images,labels=images.to(device), labels.to(device)\r\n",
        "outputs=ff_net(images)\r\n",
        "print(f1_score(torch.max(outputs.data,1)[-1].cpu(),labels.cpu(),average=\"micro\"))\r\n",
        "print(accuracy_score(torch.max(outputs.data,1)[-1].cpu(),labels.cpu()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-clqG_x6HrDo"
      },
      "source": [
        "# Making a CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "en8_qxSWIOkn"
      },
      "source": [
        "Define the convolutional network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZiZPC0WHtgi"
      },
      "source": [
        "import torch.nn.functional as F \r\n",
        "class ConvNet(nn.Module):\r\n",
        "  \r\n",
        "  def __init__(self):\r\n",
        "    super(ConvNet,self).__init__()\r\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)\r\n",
        "    self.pool = nn.MaxPool2d(2, 2)\r\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\r\n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 120)\r\n",
        "    self.fc2 = nn.Linear(120, 84)\r\n",
        "    self.fc3 = nn.Linear(84, 10)\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    x = self.pool(F.relu(self.conv1(x)))\r\n",
        "    x = self.pool(F.relu(self.conv2(x)))\r\n",
        "    x = x.view(-1, 16 * 5 * 5)\r\n",
        "    x = F.relu(self.fc1(x))\r\n",
        "    x = F.relu(self.fc2(x))\r\n",
        "    x = self.fc3(x)\r\n",
        "    return x\r\n",
        "\r\n",
        "conv_net=ConvNet()\r\n",
        "conv_net.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9EWy6qRJVEK"
      },
      "source": [
        "Reinitialize the train and test loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKbSUIZkJT-i"
      },
      "source": [
        "train_loader=torch.utils.data.DataLoader(train_data,batch_size=batch_size,shuffle=True)\r\n",
        "test_loader=torch.utils.data.DataLoader(test_data,batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcWkKWtvJkWx"
      },
      "source": [
        "Define the loss and the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRaueqW9Jlgy"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = optim.Adam(conv_net.parameters(), lr=0.0001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HuBFgxVKFyb"
      },
      "source": [
        "num_epochs=50\r\n",
        "for epoch in range(num_epochs):\r\n",
        "  running_loss=0.0\r\n",
        "\r\n",
        "  for i, data in enumerate(train_loader, 0):\r\n",
        "\r\n",
        "    # get the inputs; data is a list of [inputs, labels]\r\n",
        "    inputs, labels = data[0].to(device), data[1].to(device)\r\n",
        "\r\n",
        "    # zero the parameter gradients\r\n",
        "    optimizer.zero_grad()\r\n",
        "\r\n",
        "    # forward + backward + optimize\r\n",
        "    outputs = conv_net(inputs)\r\n",
        "    loss = criterion(outputs, labels)\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    # print statistics\r\n",
        "    running_loss += loss.item()\r\n",
        "    if i % 100 == 99:\r\n",
        "        print('[Epoch %d, Iteration %5d] loss: %.3f' %\r\n",
        "              (epoch + 1, i + 1, running_loss / 2000))\r\n",
        "        running_loss = 0.0\r\n",
        "\r\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRcjkEK4Sx0J"
      },
      "source": [
        "Testing accuracy and F1-score on first test batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrGiAoWDKcro"
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\r\n",
        "dataiter=iter(test_loader)\r\n",
        "images,labels=dataiter.next()\r\n",
        "images,labels=images.to(device), labels.to(device)\r\n",
        "outputs=conv_net(images)\r\n",
        "\r\n",
        "print(\"F1 Score: \",f1_score(torch.max(outputs.data,1)[-1].cpu(),labels.cpu(),average=\"macro\"))\r\n",
        "print(\"Accuracy: \",accuracy_score(torch.max(outputs.data,1)[-1].cpu(),labels.cpu()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jiy7LHTS20x"
      },
      "source": [
        "Compute per-class accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pCi4Sp8Q6iu"
      },
      "source": [
        "class_correct = list(0. for i in range(len(classes)))\r\n",
        "class_total = list(0. for i in range(len(classes)))\r\n",
        "for data in test_loader:\r\n",
        "  images, labels = data\r\n",
        "  images, labels = images.to(device), labels.to(device)\r\n",
        "  outputs = conv_net(images)\r\n",
        "  _, predicted = torch.max(outputs, 1)\r\n",
        "  c = (predicted == labels).squeeze()\r\n",
        "  for i in range(labels.size(0)):\r\n",
        "    label = labels[i]\r\n",
        "    class_correct[label] += c[i].item()\r\n",
        "    class_total[label] += 1\r\n",
        "\r\n",
        "\r\n",
        "for i in range(10):\r\n",
        "  print('Accuracy of %5s : %2d %%' % (\r\n",
        "    classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}